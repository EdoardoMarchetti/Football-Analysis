{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capology Player Web Scraping \n",
    "\n",
    "Notebook to scrape raw data from [Capology](https://www.capology.com) using Beatifulsoup and Selenium. \n",
    "\n",
    "In this version I will scrape only the EPL data. Check the original version [here](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/Capology%20Player%20Salary%20Web%20Scraping.ipynb) to find out data on more legues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notebook Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys, getopt\n",
    "assert sys.version_info >= (3,5)\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Math operation\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "#Datetime\n",
    "import datetime\n",
    "from datetime import date \n",
    "import time\n",
    "\n",
    "#Data Processing\n",
    "import pandas as pd\n",
    "import random\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "#Reading directories\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#Working with JSON\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "#Web Scraping\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#Data Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import missingno as msno\n",
    "\n",
    "#Progresso Bar\n",
    "import tqdm as tqdm\n",
    "\n",
    "#Display in Jupyter\n",
    "from IPython.display import Image,YouTubeVideo\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "print('Setup Complete')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Variables and Lists "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today's Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02062023'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define today's date\n",
    "today_date = datetime.datetime.now().strftime('%d/%m/%Y').replace('/','')\n",
    "today_date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2020/2021', '20/21')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season = 2020  # '2020' stands for 20/21 season\n",
    "\n",
    "#'Full season' and 'short season' string\n",
    "full_season_string = str(int(season))+'/'+str(int(season)+1)\n",
    "short_season_string = str(str(int(season))[-2:])+'/'+str(str(int(season)+1)[-2:])\n",
    "full_season_string,short_season_string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams and Legues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Premier Legue teams by season\n",
    "\n",
    "## 2016-2017 PL\n",
    "lst_teams_pl_1617 = ['arsenal', 'bournemouth', 'burnley', 'chelsea', 'crystal-palace', 'everton',\n",
    "             'hull-city', 'leicester', 'liverpool', 'manchester-city', 'manchester-united',\n",
    "             'middlesbrough', 'southampton', 'stoke-city', 'sunderland', 'swansea', 'tottenham',\n",
    "             'watford', 'west-bromwich', 'west-ham']\n",
    "\n",
    "## 2017-2018 PL\n",
    "lst_teams_pl_1718 = ['arsenal', 'bournemouth', 'brighton', 'burnley', 'chelsea', 'crystal-palace', 'everton',\n",
    "             'huddersfield', 'leicester', 'liverpool', 'manchester-city', 'manchester-united',\n",
    "             'newcastle', 'southampton', 'stoke-city', 'swansea', 'tottenham',\n",
    "             'watford', 'west-bromwich', 'west-ham']\n",
    "\n",
    "## 2018-2019 PL\n",
    "lst_teams_pl_1819 = ['arsenal', 'bournemouth', 'brighton', 'burnley', 'cardiff', 'chelsea',\n",
    "             'crystal-palace', 'everton', 'fulham', 'huddersfield', 'leicester',\n",
    "             'liverpool', 'manchester-city', 'manchester-united', 'newcastle',\n",
    "             'southampton', 'tottenham', 'watford', 'west-ham', 'wolverhampton']\n",
    "\n",
    "## 2019-2020 PL\n",
    "lst_teams_pl_1920 = ['arsenal', 'aston-villa', 'bournemouth', 'brighton', 'burnley', 'chelsea',\n",
    "             'crystal-palace', 'everton', 'leicester',\n",
    "             'liverpool', 'manchester-city', 'manchester-united', 'newcastle',\n",
    "             'norwich', 'sheffield-united', 'southampton', 'tottenham', 'watford',\n",
    "             'west-ham', 'wolverhampton']\n",
    "\n",
    "## 2020-2021 PL\n",
    "lst_teams_pl_2021 = ['arsenal', 'aston-villa', 'brighton', 'burnley', 'chelsea',\n",
    "             'crystal-palace', 'everton', 'fulham', 'leeds', 'leicester',\n",
    "             'liverpool', 'manchester-city', 'manchester-united', 'newcastle',\n",
    "             'sheffield-united', 'southampton', 'tottenham', 'west-bromwich',\n",
    "             'west-ham', 'wolverhampton']\n",
    "\n",
    "## 2021-2022 PL\n",
    "lst_teams_pl_2122 = ['arsenal', 'aston-villa', 'brentford', 'brighton', 'burnley', 'chelsea',\n",
    "             'crystal-palace', 'everton', 'leeds', 'leicester',\n",
    "             'liverpool', 'manchester-city', 'manchester-united', 'newcastle', 'norwich',\n",
    "             'southampton', 'tottenham', 'watford', 'west-ham', 'wolverhampton']\n",
    "\n",
    "## 2022-2023 PL\n",
    "lst_teams_pl_2223 = ['arsenal', 'aston-villa', 'bournemouth','brentford', 'brighton', 'chelsea',\n",
    "             'crystal-palace', 'everton', 'fulham','leeds', 'leicester',\n",
    "             'liverpool', 'manchester-city', 'manchester-united', 'newcastle', 'nottingham-forest',\n",
    "             'southampton', 'tottenham', 'west-ham', 'wolverhampton']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_seasons = ['2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/edoardo/Desktop/GitHub/Football-Analysis/eddwebster_notebooks'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join('..')\n",
    "\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "data_dir_capology = os.path.join(data_dir, 'capology')\n",
    "if not os.path.exists(data_dir_capology):\n",
    "    os.mkdir(data_dir_capology)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions (Scrapers)\n",
    "Two different scrapers:\n",
    "\n",
    "1. Previous seasons (```scrape_capology_season_prev```)\n",
    "2. Current seasons (slightly different webpage structure, so needs to be different) (```scrape_capology_season_current```)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous season scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_capology_seasons_prev(data_dir_capology, lst_teams, season, comp):\n",
    "\n",
    "    #Print statement\n",
    "    print(f'Scraping for {comp} for the {season} season has now started...')\n",
    "\n",
    "    #Create empty list for DataFrame\n",
    "    dfs_players = []\n",
    "\n",
    "    #Create the output directory\n",
    "    season_folder = os.path.join(data_dir_capology, 'raw', f'{comp}', f'{season}')\n",
    "    Path(season_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    for team in lst_teams:\n",
    "        csv_file_path = os.path.join(season_folder, f'{team}_{comp}_{season}.csv')\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            #Define the url\n",
    "            url = f'https://www.capology.com/club/{team}/salaries/{season}/'\n",
    "            #Print statement\n",
    "            print(f'Scraping {team} for the {season} season')\n",
    "\n",
    "            wd = webdriver.Chrome('chromedriver', options=options)\n",
    "            wd.get(url)\n",
    "            html = wd.page_source\n",
    "            time.sleep(5)\n",
    "            html = wd.page_source\n",
    "            #Get the last df since not all the pages have the same lenght\n",
    "            df = pd.read_html(html, header=0)[-1]\n",
    "            \n",
    "            ### Data Engineering\n",
    "            #Rename the columns\n",
    "            df = df.rename(columns = df.iloc[0])\n",
    "            df.columns = list(\n",
    "                                map(\n",
    "                                    lambda col: col if not('Pos' in col) and not('Country' in col)\\\n",
    "                                        else ('Position' if 'Pos' in col else 'Country'), list(df.columns)\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "            #Remove the first row and the last row with totals\n",
    "            df = df.iloc[1:-1,:]\n",
    "\n",
    "            #Reset the index \n",
    "            df = df.reset_index()\n",
    "\n",
    "            #Drop the index and the Rank columns\n",
    "            df = df.drop(['index'], axis = 1)\n",
    "            #Add custom columns\n",
    "            df['Team'] = team\n",
    "            df['Team'] = df['Team'].str.replace('-', ' ').str.title().str.replace('Fc', 'FC').str.replace('Ac', 'AC')\n",
    "            df['League'] = comp\n",
    "            df['League'] = df['League'].str.replace('-', ' ').str.title()\n",
    "            df['Season'] = season\n",
    "            print(f'Saving DataFrame of {team} for the {season} season')\n",
    "\n",
    "            ### Save to csv\n",
    "            df.to_csv(csv_file_path)\n",
    "\n",
    "            ### Append to joint DataFrame\n",
    "            dfs_players.append(df)\n",
    "        else:\n",
    "            df = pd.read_csv(csv_file_path, index_col=None, header=0)\n",
    "            print(f'{team} already scraped and saved for the {season} season')\n",
    "\n",
    "            ### Append to joint DataFrame\n",
    "            dfs_players.append(df)\n",
    "\n",
    "    ### Concatenate all the DFS\n",
    "    df_players_all = pd.concat(dfs_players)\n",
    "\n",
    "    ### Engineer unified data\n",
    "    df_players_all['Team'] = df_players_all['Team'].str.replace('-',' ').str.title().str.replace('Fc','FC')\n",
    "    df_players_all['Season'] = df_players_all['Season'].str.replace('-',' ').str.title()\n",
    "\n",
    "    #Save to csv\n",
    "    df_players_all.to_csv(os.path.join(season_folder,f'all_{comp}_{season}.csv'))\n",
    "\n",
    "    ### Print statement \n",
    "    print(f'Scraping for {comp} for the {season} season is now complete')\n",
    "\n",
    "    return df_players_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_capology_seasons_prev(data_dir_capology = data_dir_capology,\n",
    "                             lst_teams = lst_teams_pl_2021,\n",
    "                             season='2020-2021', \n",
    "                             comp='premier-league')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current season scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping a defined season of Capology data\n",
    "def scrape_capology_season_current(data_dir_capology,lst_teams, season, comp):\n",
    "\n",
    "\n",
    "    ### Print statement\n",
    "    print(f'Scraping for {comp} for the {season} season has now started...')\n",
    "    \n",
    "    ## Create empty list for DataFrame\n",
    "    dfs_players = []\n",
    "    \n",
    "    #Create the output directory\n",
    "    season_folder = os.path.join(data_dir_capology, 'raw', f'{comp}', f'{season}')\n",
    "    Path(season_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for team in lst_teams:\n",
    "        if not os.path.exists(os.path.join(data_dir_capology + f'/raw/{comp}/{season}/{team}_{comp}_{season}_last_updated_{today_date}.csv')):\n",
    "\n",
    "            url = f'https://www.capology.com/club/{team}/salaries/{season}/'\n",
    "            select_element_tag = 'select'\n",
    "            print(f'Scraping {team} for the {season} season')\n",
    "            wd = webdriver.Chrome('chromedriver', options=options)\n",
    "            wd.get(url)\n",
    "            html = wd.page_source\n",
    "            time.sleep(4)\n",
    "            html = wd.page_source\n",
    "            df = pd.read_html(html, header=0, attrs = {'id': 'table'})[-1]\n",
    "            \n",
    "            #Data Engineering\n",
    "            df = df.rename(columns = df.iloc[0])\n",
    "            df = df.iloc[1:]\n",
    "\n",
    "            new_columns_names = [\n",
    "                'Player',\n",
    "                'Verified',\n",
    "                'Gross P/W(GBP)',\n",
    "                'Gross P/W(GBP)',\n",
    "                'Gross P/W(GBP)',\n",
    "                'Signed',\n",
    "                'Contract Expiration',\n",
    "                'Years Remaining',\n",
    "                'Gross Remaining(GBP)',\n",
    "                'Release Clause(GBP)',\n",
    "                'Position',\n",
    "                'Detailed Position',\n",
    "                'Age',\n",
    "                'Status',\n",
    "                'Country',\n",
    "                'Active',\n",
    "                'Loan'\n",
    "            ]\n",
    "\n",
    "            df.columns = new_columns_names\n",
    "            df = df[:-1] \n",
    "            \n",
    "\n",
    "            ### Create new columns\n",
    "            df['Team'] = team\n",
    "            df['Team'] = df['Team'].str.replace('-', ' ').str.title().str.replace('Fc', 'FC').str.replace('Ac', 'AC')\n",
    "            df['League'] = comp\n",
    "            df['League'] = df['League'].str.replace('-', ' ').str.title()\n",
    "            df['Season'] = season\n",
    "            print(f'Saving DataFrame of {team} for the {season} season')\n",
    "\n",
    "            ### Save to CSV\n",
    "            df.to_csv(data_dir_capology + f'/raw/{comp}/{season}/{team}_{comp}_{season}_last_updated_{today_date}.csv')\n",
    "\n",
    "            ### Append to joint DataFrame\n",
    "            dfs_players.append(df)\n",
    "        else:\n",
    "            df = pd.read_csv(data_dir_capology + f'/raw/{comp}/{season}/{team}_{comp}_{season}_last_updated_{today_date}.csv', index_col=None, header=0)\n",
    "            print(f'{team} already scraped and saved for the {season} season')\n",
    "\n",
    "            ### Append to joint DataFrame\n",
    "            dfs_players.append(df)\n",
    "        \n",
    "    ## Concatenate DataFrames to one DataFrame\n",
    "    df_players_all = pd.concat(dfs_players)\n",
    "\n",
    "    ## Engineer unified data\n",
    "    df_players_all['Team'] = df_players_all['Team'].str.replace('-', ' ').str.title().str.replace('Fc', 'FC')\n",
    "    df_players_all['League'] = df_players_all['League'].str.replace('-', ' ').str.title()\n",
    "    df_players_all = df_players_all.drop(df.columns[1], axis=1)\n",
    "\n",
    "    ## Save to CSV\n",
    "    df_players_all.to_csv(data_dir_capology + f'/raw/{comp}/{season}/all_{comp}_{season}_last_updated_{todays_date}.csv')\n",
    "    \n",
    "    ### Print statement\n",
    "    print(f'Scraping for {comp} for the {season} season is now complete')\n",
    "    \n",
    "    ## Return unified season dataset\n",
    "    return df_players_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for premier-league for the 2022-2023 season has now started...\n",
      "Scraping arsenal for the 2022-2023 season\n",
      "Saving DataFrame of arsenal for the 2022-2023 season\n",
      "Scraping aston-villa for the 2022-2023 season\n",
      "Saving DataFrame of aston-villa for the 2022-2023 season\n",
      "Scraping bournemouth for the 2022-2023 season\n",
      "Saving DataFrame of bournemouth for the 2022-2023 season\n",
      "Scraping brentford for the 2022-2023 season\n",
      "Saving DataFrame of brentford for the 2022-2023 season\n",
      "Scraping brighton for the 2022-2023 season\n",
      "Saving DataFrame of brighton for the 2022-2023 season\n",
      "Scraping chelsea for the 2022-2023 season\n",
      "Saving DataFrame of chelsea for the 2022-2023 season\n",
      "Scraping crystal-palace for the 2022-2023 season\n",
      "Saving DataFrame of crystal-palace for the 2022-2023 season\n",
      "Scraping everton for the 2022-2023 season\n",
      "Saving DataFrame of everton for the 2022-2023 season\n",
      "Scraping fulham for the 2022-2023 season\n",
      "Saving DataFrame of fulham for the 2022-2023 season\n",
      "Scraping leeds for the 2022-2023 season\n",
      "Saving DataFrame of leeds for the 2022-2023 season\n",
      "Scraping leicester for the 2022-2023 season\n",
      "Saving DataFrame of leicester for the 2022-2023 season\n",
      "Scraping liverpool for the 2022-2023 season\n",
      "Saving DataFrame of liverpool for the 2022-2023 season\n",
      "Scraping manchester-city for the 2022-2023 season\n",
      "Saving DataFrame of manchester-city for the 2022-2023 season\n",
      "Scraping manchester-united for the 2022-2023 season\n",
      "Saving DataFrame of manchester-united for the 2022-2023 season\n",
      "Scraping newcastle for the 2022-2023 season\n",
      "Saving DataFrame of newcastle for the 2022-2023 season\n",
      "Scraping nottingham-forest for the 2022-2023 season\n",
      "Saving DataFrame of nottingham-forest for the 2022-2023 season\n",
      "Scraping southampton for the 2022-2023 season\n",
      "Saving DataFrame of southampton for the 2022-2023 season\n",
      "Scraping tottenham for the 2022-2023 season\n",
      "Saving DataFrame of tottenham for the 2022-2023 season\n",
      "Scraping west-ham for the 2022-2023 season\n",
      "Saving DataFrame of west-ham for the 2022-2023 season\n",
      "Scraping wolverhampton for the 2022-2023 season\n",
      "Saving DataFrame of wolverhampton for the 2022-2023 season\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'todays_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8653/751659515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m scrape_capology_season_current(data_dir_capology = data_dir_capology,\n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0mlst_teams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst_teams_pl_2223\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mseason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2022-2023'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              comp='premier-league')\n",
      "\u001b[0;32m/tmp/ipykernel_8653/3456375830.py\u001b[0m in \u001b[0;36mscrape_capology_season_current\u001b[0;34m(data_dir_capology, lst_teams, season, comp)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m## Save to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mdf_players_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir_capology\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'/raw/{comp}/{season}/all_{comp}_{season}_last_updated_{todays_date}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m### Print statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'todays_date' is not defined"
     ]
    }
   ],
   "source": [
    "scrape_capology_season_current(data_dir_capology = data_dir_capology,\n",
    "                             lst_teams = lst_teams_pl_2223,\n",
    "                             season='2022-2023', \n",
    "                             comp='premier-league')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Player', 'Player'), (nan, 'Verified'), ('Gross P/W(GBP)', 'Gross P/W(GBP)'), ('Gross P/Y(GBP)', 'Gross P/W(GBP)'), ('Gross P/Y(GBP)', 'Gross P/W(GBP)'), ('Signed', 'Signed'), ('Contract Expiration\\xa0Jun 30, 2023Jun 30, 2024Jun 30, 2025Jun 30, 2026Jun 30, 2027Jun 30, 2028', 'Contract Expiration'), ('Years Remaining\\xa0123456', 'Years Remaining'), ('Gross Remaining(GBP)', 'Gross Remaining(GBP)'), ('Release Clause(GBP)', 'Release Clause(GBP)'), ('Pos.\\xa0DFKM', 'Position'), ('Pos.\\xa0AMCBCFDMGKLBLWRBRMRW', 'Detailed Position'), ('Age', 'Age'), ('Status\\xa0ReserveStarter', 'Status'), ('Country', 'Country'), ('Active', 'Active'), ('Loan', 'Loan')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Gross P/W(GBP)</th>\n",
       "      <th>Gross P/W(GBP)</th>\n",
       "      <th>Gross P/W(GBP)</th>\n",
       "      <th>Signed</th>\n",
       "      <th>Contract Expiration</th>\n",
       "      <th>Years Remaining</th>\n",
       "      <th>Gross Remaining(GBP)</th>\n",
       "      <th>Release Clause(GBP)</th>\n",
       "      <th>Position</th>\n",
       "      <th>Detailed Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "      <th>Country</th>\n",
       "      <th>Active</th>\n",
       "      <th>Loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Emile Smith Rowe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£ 40,000</td>\n",
       "      <td>£ 2,080,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 22, 2021</td>\n",
       "      <td>Jun 30, 2026</td>\n",
       "      <td>4</td>\n",
       "      <td>£ 8,320,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>AM</td>\n",
       "      <td>22</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rob Holding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£ 40,000</td>\n",
       "      <td>£ 2,080,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan 12, 2021</td>\n",
       "      <td>Jun 30, 2024</td>\n",
       "      <td>2</td>\n",
       "      <td>£ 4,160,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>CB</td>\n",
       "      <td>27</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>William Saliba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£ 40,000</td>\n",
       "      <td>£ 2,080,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 25, 2019</td>\n",
       "      <td>Jun 30, 2024</td>\n",
       "      <td>2</td>\n",
       "      <td>£ 4,160,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>CB</td>\n",
       "      <td>21</td>\n",
       "      <td>Starter</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Matt Turner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£ 35,000</td>\n",
       "      <td>£ 1,820,000</td>\n",
       "      <td>£ 660,000</td>\n",
       "      <td>Jul 1, 2022</td>\n",
       "      <td>Jun 30, 2025</td>\n",
       "      <td>3</td>\n",
       "      <td>£ 5,460,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K</td>\n",
       "      <td>GK</td>\n",
       "      <td>28</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Reiss Nelson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£ 15,000</td>\n",
       "      <td>£ 780,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aug 31, 2018</td>\n",
       "      <td>Jun 30, 2023</td>\n",
       "      <td>1</td>\n",
       "      <td>£ 780,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>RW</td>\n",
       "      <td>23</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player  Verified Gross P/W(GBP) Gross P/W(GBP) Gross P/W(GBP)  \\\n",
       "19  Emile Smith Rowe       NaN       £ 40,000    £ 2,080,000            NaN   \n",
       "20       Rob Holding       NaN       £ 40,000    £ 2,080,000            NaN   \n",
       "21    William Saliba       NaN       £ 40,000    £ 2,080,000            NaN   \n",
       "22       Matt Turner       NaN       £ 35,000    £ 1,820,000      £ 660,000   \n",
       "23      Reiss Nelson       NaN       £ 15,000      £ 780,000            NaN   \n",
       "\n",
       "          Signed Contract Expiration Years Remaining Gross Remaining(GBP)  \\\n",
       "19  Jul 22, 2021        Jun 30, 2026               4          £ 8,320,000   \n",
       "20  Jan 12, 2021        Jun 30, 2024               2          £ 4,160,000   \n",
       "21  Jul 25, 2019        Jun 30, 2024               2          £ 4,160,000   \n",
       "22   Jul 1, 2022        Jun 30, 2025               3          £ 5,460,000   \n",
       "23  Aug 31, 2018        Jun 30, 2023               1            £ 780,000   \n",
       "\n",
       "   Release Clause(GBP) Position Detailed Position Age   Status        Country  \\\n",
       "19                 NaN        F                AM  22  Reserve        England   \n",
       "20                 NaN        D                CB  27  Reserve        England   \n",
       "21                 NaN        D                CB  21  Starter         France   \n",
       "22                 NaN        K                GK  28  Reserve  United States   \n",
       "23                 NaN        F                RW  23  Reserve        England   \n",
       "\n",
       "   Active Loan  \n",
       "19    NaN  NaN  \n",
       "20    NaN  NaN  \n",
       "21    NaN  NaN  \n",
       "22    NaN  NaN  \n",
       "23    NaN  NaN  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova = df[0].copy()\n",
    "prova = prova.rename(columns = prova.iloc[0])\n",
    "prova = prova.iloc[1:]\n",
    "#prova = prova.dropna(axis=1, how='all')\n",
    "\n",
    "new_columns_names = [\n",
    "    'Player',\n",
    "    'Verified',\n",
    "    'Gross P/W(GBP)',\n",
    "    'Gross P/W(GBP)',\n",
    "    'Gross P/W(GBP)',\n",
    "    'Signed',\n",
    "    'Contract Expiration',\n",
    "    'Years Remaining',\n",
    "    'Gross Remaining(GBP)',\n",
    "    'Release Clause(GBP)',\n",
    "    'Position',\n",
    "    'Detailed Position',\n",
    "    'Age',\n",
    "    'Status',\n",
    "    'Country',\n",
    "    'Active',\n",
    "    'Loan'\n",
    "]\n",
    "\n",
    "prova.columns = new_columns_names\n",
    "prova = prova[:-1] \n",
    "prova.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
